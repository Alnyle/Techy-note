
In supervised learning, we use a model to make predictions based on given data. One common type of supervised learning is linear regression, where we try to fit a straight line to the data. For example, let's say we want to predict the price of a house based on its size. We can use a dataset of house sizes and prices to train our model. Once trained, the model can predict the price of a new house based on its size.

To understand linear regression, imagine you're a real estate agent helping a client sell her house. You measure the size of the house and find it to be 1250 square feet. By using linear regression, you can draw a straight line that best fits the data points in the dataset. This line represents the relationship between house size and price. Based on this line, you can estimate that the house with a size of 1250 square feet might sell for around $220,000.

Linear regression is just one example of a supervised learning model. It's called a regression model because it predicts numbers, like prices. There are other models for different types of problems, such as classification models that predict categories, like whether a picture is of a cat or a dog. In supervised learning, we provide the model with data that has the correct answers, so it can learn to make accurate predictions.


1. Dependent Variable: Also known as the target variable or output variable, it is the variable that we want to predict or estimate using the independent variables.
    
2. Independent Variable: Also known as the input variable or feature, it is the variable(s) that are used to predict or estimate the dependent variable.


The **notations** commonly used for dependent and independent variables are as follows:

- **Dependent Variable (Target Variable)**:
    
    - Typically denoted as **Y** (uppercase).
    - In machine learning and statistics, it's the variable being predicted.
    - Sometimes, in classification problems, the dependent variable might also be referred to as **y* (for individual data points) or **yâ€‹** (for predicted values).
- **Independent Variables (Input/Feature Variables)**:
    
    - Typically denoted as **X** (uppercase), representing the matrix of features (when there are multiple independent variables).
    - For individual features, they are denoted as x1,x2  where **n** represents the number of features.
    - Sometimes, the entire input vector for a single data point is represented as **x** for individual observations.

     ![[vlcsnap-2024-10-04-16h42m31s959.png]]

    ![[C1_W1_L3_S1_Lecture_b.png]]